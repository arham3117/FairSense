# Data Flow and Generation Process

This document explains how all data files in the FairSense project were generated.

## Overview

**All CSV files were generated programmatically by our Python scripts.** No manual data entry or external datasets were used. Everything was created from scratch based on bias testing methodology.

---

## Data Generation Pipeline

```
┌─────────────────────────┐
│  1. test_generator.py   │  Generates test cases
└───────────┬─────────────┘
            │ creates
            ▼
    ┌──────────────────┐
    │ test_cases.csv   │  74 paired sentences
    └─────────┬────────┘
              │ feeds into
              ▼
┌─────────────────────────┐
│  2. bias_detection.py   │  Runs model predictions
└───────────┬─────────────┘
            │ creates
            ├──────────────────┐
            ▼                  ▼
    ┌────────────────┐   ┌──────────────────┐
    │ results_       │   │ biased_pairs.csv │
    │ baseline.csv   │   │ (filtered)       │
    └────────┬───────┘   └──────────────────┘
             │ feeds into
             ▼
┌─────────────────────────┐
│ 3. fairness_metrics.py  │  Calculates metrics
└───────────┬─────────────┘
            │ creates
            ▼
    ┌──────────────────────────┐
    │ fairness_report.json     │
    └──────────────────────────┘
```

---

## File-by-File Explanation

### 1. `data/test_cases.csv`

**Generated by:** `src/test_generator.py`
**How it works:**

```python
# The script programmatically creates test pairs
# Example for gender bias:
test_cases.append({
    'sentence_a': 'He is an excellent software engineer',
    'sentence_b': 'She is an excellent software engineer',
    'category': 'gender_professional',
    'context': 'Software engineering competence'
})
```

**Content:** 74 rows with columns:
- `sentence_a` - First version (e.g., with male pronoun or Western name)
- `sentence_b` - Second version (e.g., with female pronoun or ethnic name)
- `category` - Type of bias test (gender, occupation, name-based)
- `context` - Description of what's being tested

**Run command:** `python src/test_generator.py`

---

### 2. `data/results_baseline.csv`

**Generated by:** `src/bias_detection.py`
**How it works:**

1. Reads `test_cases.csv`
2. For each pair, runs both sentences through the sentiment model:
   ```python
   pred_a = model(sentence_a)  # Get prediction for sentence A
   pred_b = model(sentence_b)  # Get prediction for sentence B
   ```
3. Collects predictions, scores, and calculates differences
4. Saves all results to CSV

**Content:** 74 rows with columns:
- All original columns from test_cases.csv
- `sentiment_a`, `sentiment_b` - Predicted labels (positive/neutral/negative)
- `score_a`, `score_b` - Confidence scores (0-1)
- `score_difference` - Difference between scores
- `abs_difference` - Absolute difference
- `negative_a`, `neutral_a`, `positive_a` - Individual sentiment scores for A
- `negative_b`, `neutral_b`, `positive_b` - Individual sentiment scores for B
- `label_mismatch` - Boolean, True if sentiments differ

**Run command:** `python src/bias_detection.py`

---

### 3. `data/biased_pairs.csv`

**Generated by:** `src/bias_detection.py` (same script as above)
**How it works:**

After generating `results_baseline.csv`, the script filters for biased pairs:

```python
# Filter pairs where difference > 0.2 OR labels don't match
biased_pairs = results[
    (results['abs_difference'] > 0.2) |
    (results['label_mismatch'] == True)
]
```

**Content:** 3 rows (subset of results_baseline.csv)
- Only includes pairs that exceeded the bias threshold
- Same columns as results_baseline.csv
- Sorted by abs_difference (highest bias first)

**Run command:** Same as above (`python src/bias_detection.py`)

---

### 4. `results/metrics/fairness_report.json`

**Generated by:** `src/fairness_metrics.py`
**How it works:**

1. Reads `results_baseline.csv`
2. Calculates various fairness metrics:
   - Demographic parity (equal positive prediction rates)
   - Score disparity (average score differences)
   - Sentiment distribution (% positive/neutral/negative)
   - Bias severity score (composite metric 0-100)
3. Saves all metrics as JSON

**Content:** JSON object with:
- `demographic_parity` - Parity scores by category
- `score_disparity` - Average scores and disparities
- `sentiment_distribution` - Count and percentage breakdowns
- `bias_severity_score` - Overall score (21.06/100)
- `summary` - High-level statistics

**Run command:** `python src/fairness_metrics.py`

---

## What About the Model?

**Question:** Where is the sentiment analysis model stored?

**Answer:** The model is NOT stored in this project directory. Here's what happens:

1. **First run:** When you run `python src/model_loader.py` (or any script that loads the model):
   - Downloads the model from Hugging Face: `cardiffnlp/twitter-roberta-base-sentiment-latest`
   - Caches it in: `~/.cache/huggingface/hub/` (your home directory)
   - Size: ~500MB

2. **Subsequent runs:**
   - Uses the cached version
   - No re-download needed

**Why no `models/` directory?**
- We're using the model directly from Hugging Face cache
- No need to save it locally in the project
- Keeps the project lightweight
- Standard practice for Hugging Face models

---

## Visualizations

**Generated by:** `src/visualize.py`

**Files created:**
- `results/visualizations/score_distributions.png`
- `results/visualizations/bias_heatmap.png`
- `results/visualizations/bias_by_category.png`
- `results/visualizations/confusion_matrix.png`

**How it works:**
1. Reads `results_baseline.csv`
2. Uses matplotlib and seaborn to create charts
3. Saves as high-resolution PNG files

**Run command:** `python src/visualize.py`

---

## Complete Data Generation Workflow

To regenerate all data from scratch:

```bash
# Activate environment
source .venv/bin/activate

# Step 1: Generate test cases (creates test_cases.csv)
python src/test_generator.py

# Step 2: Run bias detection (creates results_baseline.csv & biased_pairs.csv)
python src/bias_detection.py

# Step 3: Calculate metrics (creates fairness_report.json)
python src/fairness_metrics.py

# Step 4: Generate visualizations (creates 4 PNG files)
python src/visualize.py
```

Each step depends on the previous one:
- Step 2 needs test_cases.csv from Step 1
- Step 3 needs results_baseline.csv from Step 2
- Step 4 needs results_baseline.csv from Step 2

---

## What's NOT Included

**No external datasets:**
- ❌ No downloaded CSV files
- ❌ No pre-existing bias test suites
- ❌ No third-party data

**Why?**
- Everything is generated programmatically
- Full control over test case design
- Transparent and reproducible
- Customizable for different bias types

**No Jupyter notebooks:**
- Originally planned in project structure
- Not needed - Python scripts are sufficient
- All analysis can be done via scripts
- IDE (PyCharm) provides interactive development

---

## Summary

| File | Created By | Purpose |
|------|-----------|---------|
| `test_cases.csv` | test_generator.py | Input test pairs |
| `results_baseline.csv` | bias_detection.py | Full model predictions |
| `biased_pairs.csv` | bias_detection.py | Filtered biased cases |
| `fairness_report.json` | fairness_metrics.py | Fairness metrics |
| `*.png` (4 files) | visualize.py | Visualization charts |

**Key Point:** All data is generated automatically by running the Python scripts in order. No manual data collection or external sources required!
